{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e8f1c8-44e8-461d-9a12-13e714448fa1",
   "metadata": {},
   "source": [
    "# RFP Response Generation Workflow\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llamacloud-demo/blob/main/examples/report_generation/rfp_response/generate_rfp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook shows you how to build a workflow to generate a response to an RFP. \n",
    "\n",
    "In this scenario, we assume that you are Microsoft, and you are responding to the [JEDI Cloud RFP](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf) put out by the federal government. The government is using the submitted responses to decide the best vendor for their needs.\n",
    "\n",
    "![generate_rfp_img](generate_rfp_img.png)\n",
    "\n",
    "We index a set of relevant documents that Microsoft has - including its annual report, wikipedia page on Microsoft Azure, a slide deck on the government cloud and cybersecurity capabilities. We then help you build an agentic workflow that can ingest an RFP, and generate a response for it in \n",
    "a way that adheres to its guidelines.\n",
    "\n",
    "We use LlamaCloud to index the documents and get back a set of retrieval endpoints over the documents. This tutorial takes full advantage of LlamaCloud as an e2e RAG platform. If you want to check out a similar tutorial that uses the LlamaParse API, check this other [tutorial out instead](https://github.com/run-llama/llama_parse/blob/main/examples/report_generation/rfp_response/generate_rfp.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54d79c-efa5-43dc-a417-eef4a7e22833",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-indices-llama-cloud llama-cloud llama-parse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f28c6a-cb5e-4c16-bdc7-a69817fc4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7137b3-5b37-4e52-bc46-b994693d2664",
   "metadata": {},
   "source": [
    "## Setup LlamaCloud Index\n",
    "\n",
    "We download the context documents for Microsoft to form the knowledge base.\n",
    "1. Microsoft 2024 10-K \n",
    "2. Azure Wikipedia page\n",
    "3. A slide deck on Microsoft Azure Government\n",
    "4. Microsoft Digital Defense Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310efa-1422-4214-b0bf-41b6e163fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microsoft annual report\n",
    "!wget \"https://www.dropbox.com/scl/fi/4v5dx8dc9yqc8k0yw5g4h/msft_10k_2024.pdf?rlkey=jdyfrsoyb18ztlq5msunmibns&st=9w6bdyvn&dl=1\" -O data/msft_10k_2024.pdf\n",
    "# !wget \"https://microsoft.gcs-web.com/static-files/1c864583-06f7-40cc-a94d-d11400c83cc8\" -O data/msft_10k_2024.pdf\n",
    "\n",
    "# azure wikipedia page\n",
    "!wget \"https://www.dropbox.com/scl/fi/7waur8ravmve3fe8nej0k/azure_wiki.pdf?rlkey=icru2w64oylx1p76ftt6y9irv&st=fr87vxob&dl=1\" -O data/azure_wiki.pdf\n",
    "# azure government slide deck\n",
    "!wget \"https://cdn.ymaws.com/flclerks.site-ym.com/resource/resmgr/2017_Fall_Conf/Presentations/2018-10-12_FCCC_Microsoft_Az.pdf\" -O data/azure_gov.pdf\n",
    "# microsoft cybersecurity capabilities\n",
    "!wget \"https://www.dropbox.com/scl/fi/qh00xz29rlom4md8ce675/microsoft_ddr.pdf?rlkey=d868nbnsu1ng41y1chw69y64b&st=24iqemb1&dl=1\" -O data/msft_ddr.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28f1ce-9618-47a2-9fc9-0502a382d841",
   "metadata": {},
   "source": [
    "We then upload these documents to LlamaCloud. For best results:\n",
    "- Use \"3rd Party multi-modal model\" in the Parse Settings\n",
    "- Use Page-level segmentation and \"None\" for chunking configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf530f9-4337-4303-be60-35df7b55d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data_out_rfp: File exists\n"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "\n",
    "index = LlamaCloudIndex(\n",
    "  name=\"<index_name>\", \n",
    "  project_name=\"<project_name>\",\n",
    "  organization_id=\"<organization_id>\",\n",
    "  # api_key=\"llx-...\"\n",
    ")\n",
    "# enter your pipeline/index ID as wells\n",
    "pipeline_id = \"<pipeline_id>\"\n",
    "\n",
    "# define data output directory\n",
    "data_out_dir = \"data_out_rfp\"\n",
    "!mkdir {data_out_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ea867-bdf1-4bd9-9858-9bcc3eacfdcd",
   "metadata": {},
   "source": [
    "We then do a pass to generate summaries as metadata, and attach those onto the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9670e972-9c2e-4437-8fb9-fc63004ca393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_cloud.client import LlamaCloud\n",
    "import os\n",
    "\n",
    "# setup client\n",
    "os.environ[\"LLAMA_CLOUD_BASE_URL\"] = \"https://api.cloud.llamaindex.ai\"\n",
    "client = LlamaCloud(\n",
    "    token=os.environ[\"LLAMA_CLOUD_API_KEY\"],\n",
    "    base_url=os.environ[\"LLAMA_CLOUD_BASE_URL\"]\n",
    ")\n",
    "pipeline_docs = client.pipelines.list_pipeline_documents(pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f842432a-0060-44ce-8438-cba21c82238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_size': 20147265,\n",
       " 'last_modified_at': '2024-10-20T04:29:30',\n",
       " 'file_path': 'msft_ddr.pdf',\n",
       " 'file_name': 'msft_ddr.pdf',\n",
       " 'pipeline_id': '8788cb8e-34d1-4402-aebf-b52a4dc8fdf3',\n",
       " 'summary': 'The Microsoft Digital Defense Report, published in October 2023, provides insights into the evolving cyber threat landscape from July 2022 to June 2023, highlighting key developments in cybercrime, nation-state threats, and the importance of collaboration in enhancing global cybersecurity resilience.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pipeline_docs))\n",
    "pipeline_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15985be9-690b-41c2-a495-5f24f0578be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Generated summary: This file provides a comprehensive overview of Microsoft Azure, covering its history, various cloud services, deployment models, and key features such as AI capabilities, identity management, and storage solutions.\n",
      ">> Generated summary: The document is the Microsoft Digital Defense Report, published in October 2023, which analyzes the evolving cyber threat landscape from July 2022 to June 2023, focusing on developments in cybercrime, nation-state threats, and the significance of collaboration in enhancing global cybersecurity resilience.\n",
      ">> Generated summary: This file is Microsoft's Annual Report on Form 10-K for the fiscal year ended June 30, 2023, which outlines the company's business operations, financial performance, and strategic initiatives, highlighting significant growth in cloud services and investments in artificial intelligence.\n",
      ">> Generated summary: This file provides an overview of Microsoft Azure Government, detailing its secure and compliant cloud services designed for U.S. government entities, along with insights on digital transformation, cloud service models, and compliance standards. It highlights the platform's commitment to trust, privacy, and innovation in supporting government operations.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "summary_llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# generate summaries and attach as metadata on the docs\n",
    "for pipeline_doc in pipeline_docs:\n",
    "    doc = Document.from_cloud_document(pipeline_doc)\n",
    "    index = SummaryIndex([doc])\n",
    "    response = index.as_query_engine(llm=summary_llm).query(\n",
    "        \"Generate a short 1-2 line summary of this file to help inform an agent on what this file is about.\"\n",
    "    )\n",
    "    print(f\">> Generated summary: {str(response)}\")\n",
    "    # change the metadata of the document\n",
    "    pipeline_doc.metadata[\"summary\"] = str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2502f6da-9a3e-41cb-9924-52129f60f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_size': 1286244,\n",
       " 'last_modified_at': '2024-10-20T04:29:30',\n",
       " 'file_path': 'azure_wiki.pdf',\n",
       " 'file_name': 'azure_wiki.pdf',\n",
       " 'pipeline_id': '8788cb8e-34d1-4402-aebf-b52a4dc8fdf3',\n",
       " 'summary': 'This file provides an overview of Microsoft Azure, detailing its history, services, deployment models, and key features, including cloud computing capabilities, identity management, storage solutions, and AI services.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upsert new documents to vector database\n",
    "upserted_docs = client.pipelines.upsert_batch_pipeline_documents(pipeline_id, request=pipeline_docs)\n",
    "upserted_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430fd045-f1a4-47c2-a773-718608d4c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify metadata has been inserted and get file names\n",
    "pipeline_docs = client.pipelines.list_pipeline_documents(pipeline_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c4446-c477-4261-9747-c5294b0a54e9",
   "metadata": {},
   "source": [
    "### Define Retrievers\n",
    "\n",
    "Define retrievers, one for each file. \n",
    "\n",
    "With LlamaCloud, you can get access to both **chunk** and **document**-level retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbac9ab-e3e2-448f-9e74-ad995415fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from pathlib import Path\n",
    "from typing import Optional, List\n",
    "\n",
    "DOC_RETRIEVE_PREFIX = \"\"\"\\\n",
    "Synthesizes an answer to your question by feeding in in the entire relevant document as context. Best used for higher-level summarization options.\n",
    "Do NOT use if answer can be found in a specific chunk of a given document. Use the chunk_query_engine instead for that purpose.\n",
    "\n",
    "Document: {file_name}\n",
    "\"\"\"\n",
    "\n",
    "CHUNK_RETRIEVE_PREFIX = \"\"\"\\\n",
    "Synthesizes an answer to your question by feeding in relevant chunks of a document as context. Best used for questions that are more pointed in nature.\n",
    "Do NOT use if the question asks seems to require a general summary of any given document. Use the doc_query_engine instead for that purpose.\n",
    "\n",
    "Document: {file_name}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# function tools\n",
    "def generate_tool(\n",
    "    file: str, \n",
    "    file_description: Optional[str] = None,\n",
    "    retrieve_document: bool = False\n",
    "):\n",
    "    \"\"\"Return a function that retrieves only within a given file.\"\"\"\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(key=\"file_path\", operator=FilterOperator.EQ, value=file),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def chunk_retriever_fn(query: str) -> str:\n",
    "        retriever = index.as_retriever(similarity_top_k=5, filters=filters)\n",
    "        nodes = retriever.retrieve(query)\n",
    "\n",
    "        full_text = \"\\n\\n========================\\n\\n\".join(\n",
    "            [n.get_content(metadata_mode=\"all\") for n in nodes]\n",
    "        )\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    # define name as a function of the file\n",
    "    fn_name = Path(file).stem + \"_retrieve\"\n",
    "\n",
    "    tool_description_tmpl = DOC_RETRIEVE_PREFIX if retrieve_document else CHUNK_RETRIEVE_PREFIX\n",
    "    tool_description = tool_description_tmpl.format(file_name=file)\n",
    "    if file_description is not None:\n",
    "        tool_description += f\"\\n\\nFile Description: {file_description}\"\n",
    "\n",
    "    tool = FunctionTool.from_defaults(\n",
    "        fn=chunk_retriever_fn, name=fn_name, description=tool_description\n",
    "    )\n",
    "\n",
    "    return tool\n",
    "\n",
    "\n",
    "# generate tools - include both chunk-level and document-level retrieval\n",
    "tools = []\n",
    "for pipeline_doc in pipeline_docs:\n",
    "    # chunk-level tool\n",
    "    file_name = pipeline_doc.metadata[\"file_name\"]\n",
    "    summary = pipeline_doc.metadata[\"summary\"]\n",
    "    tools.append(generate_tool(file_name, file_description=summary))\n",
    "    # document-level tool\n",
    "    tools.append(\n",
    "        generate_tool(\n",
    "            file_name, \n",
    "            file_description=summary,\n",
    "            retrieve_document=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9106c7d-8c43-4443-a192-94d5f3a54ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMetadata(description='Synthesizes an answer to your question by feeding in relevant chunks of a document as context. Best used for questions that are more pointed in nature.\\nDo NOT use if the question asks seems to require a general summary of any given document. Use the doc_query_engine instead for that purpose.\\n\\nDocument: msft_ddr.pdf\\n\\n\\nFile Description: The Microsoft Digital Defense Report, published in October 2023, provides insights into the evolving cyber threat landscape from July 2022 to June 2023, highlighting key developments in cybercrime, nation-state threats, and the importance of collaboration in enhancing global cybersecurity resilience.', name='msft_ddr_retrieve', fn_schema=<class 'llama_index.core.tools.utils.msft_ddr_retrieve'>, return_direct=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate an existing function\n",
    "tools[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ebbad-3200-4818-aa48-705eda21503e",
   "metadata": {},
   "source": [
    "## Build Workflow\n",
    "\n",
    "Let's build a workflow that can iterate through the extracted keys/questions from the RFP, and fill them out! \n",
    "\n",
    "The user specifies an RFP document as input. The workflow then goes through the following steps:\n",
    "1. We parse the RFP template using LlamaParse\n",
    "2. We then extract out the relevant questions we'd want to ask the knowledge base given the instructions in the RFP\n",
    "3. For each question, we query the knowledge base using a specialized agent to generate a response. The agent is equipped with a set of retrieval tools over the data.\n",
    "4. We concatenate the questions/answers into a list of dictionaries.\n",
    "5. Given the question/answer pairs, we feed it along with the source RFP template into a prompt to generate the final report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec43f2-125b-4657-9fb7-ab733d1b0b59",
   "metadata": {},
   "source": [
    "We download the [JEDI RFP template](https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad2382b2-fa5a-4b59-808f-3b9f22aa2eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-19 22:21:53--  https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\n",
      "Resolving imlive.s3.amazonaws.com (imlive.s3.amazonaws.com)... 52.219.193.121, 52.219.220.161, 52.219.220.73, ...\n",
      "Connecting to imlive.s3.amazonaws.com (imlive.s3.amazonaws.com)|52.219.193.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 864798 (845K) [application/pdf]\n",
      "Saving to: ‘data/jedi_cloud_rfp.pdf’\n",
      "\n",
      "data/jedi_cloud_rfp 100%[===================>] 844.53K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-10-19 22:21:53 (18.9 MB/s) - ‘data/jedi_cloud_rfp.pdf’ saved [864798/864798]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download JEDI Cloud RFP Template\n",
    "!mkdir -p data\n",
    "!wget \"https://imlive.s3.amazonaws.com/Federal%20Government/ID151830346965529215587195222610265670631/HQ0034-18-R-0077.pdf\" -O data/jedi_cloud_rfp.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c11c6-9af0-4dde-91f0-c3a213b7a0e5",
   "metadata": {},
   "source": [
    "We setup LlamaParse (accurate/markdown mode) to parse the RFP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395e81bb-295f-47a4-a298-fcd645ec3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "# use our multimodal models for extractions\n",
    "parser = LlamaParse(result_type=\"markdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740535e8-714b-4744-a515-5007834eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.core.llms import LLM\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# this is the research agent's system prompt, tasked with answering a specific question\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a research agent tasked with filling out a specific form key/question with the appropriate value, given a bank of context.\n",
    "You are given a specific form key/question. Think step-by-step and use the existing set of tools to help answer the question.\n",
    "\n",
    "You MUST always use at least one tool to answer each question. Only after you've determined that existing tools do not \\\n",
    "answer the question should you try to reason from first principles and prior knowledge to answer the question.\n",
    "\n",
    "You MUST try to answer the question instead of only saying 'I dont know'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the prompt tasked with extracting information from an RFP file.\n",
    "EXTRACT_KEYS_PROMPT = \"\"\"\\\n",
    "You are provided an entire RFP document, or a large subsection from it. \n",
    "\n",
    "We wish to generate a response to the RFP in a way that adheres to the instructions within the RFP, \\\n",
    "including the specific sections that an RFP response should contain, and the content that would need to go \\\n",
    "into each section.\n",
    "\n",
    "Your task is to extract out a list of \"questions\", where each question corresponds to a specific section that is required in the RFP response.\n",
    "Put another way, after we extract out the questions we will go through each question and answer each one \\\n",
    "with our downstream research assistant, and the combined\n",
    "question:answer pairs will constitute the full RFP response.\n",
    "\n",
    "You must TRY to extract out questions that can be answered by the provided knowledge base. We provide the list of file metadata below. \n",
    "\n",
    "Additional requirements:\n",
    "- Try to make the questions SPECIFIC given your knowledge of the RFP and the knowledge base. Instead of asking a question like \\\n",
    "\"How do we ensure security\" ask a question that actually addresses a security requirement in the RFP and can be addressed by the knowledge base.\n",
    "- Make sure the questions are comprehensive and addresses all the RFP requirements.\n",
    "- Make sure each question is descriptive - this gives our downstream assistant context to fill out the value for that question \n",
    "- Extract out all the questions as a list of strings.\n",
    "\n",
    "\n",
    "Knowledge Base Files:\n",
    "{file_metadata}\n",
    "\n",
    "RFP Full Template:\n",
    "{rfp_text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# this is the prompt that generates the final RFP response given the original template text and question-answer pairs.\n",
    "GENERATE_OUTPUT_PROMPT = \"\"\"\\\n",
    "You are an expert analyst.\n",
    "Your task is to generate an RFP response according to the given RFP and question/answer pairs.\n",
    "\n",
    "You are given the following RFP and qa pairs:\n",
    "\n",
    "<rfp_document>\n",
    "{output_template}\n",
    "</rfp_document>\n",
    "\n",
    "<question_answer_pairs>\n",
    "{answers}\n",
    "</question_answer_pairs>\n",
    "\n",
    "Not every question has an appropriate answer. This is because the agent tasked with answering the question did not have the right context to answer it.\n",
    "If this is the case, you MUST come up with an answer that is reasonable. You CANNOT say that you are unsure in any area of the RFP response.\n",
    "\n",
    "\n",
    "Please generate the output according to the template and the answers, in markdown format.\n",
    "Directly output the generated markdown content, do not add any additional text, such as \"```markdown\" or \"Here is the output:\".\n",
    "Follow the original format of the template as closely as possible, and fill in the answers into the appropriate sections.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class OutputQuestions(BaseModel):\n",
    "    \"\"\"List of keys that make up the sections of the RFP response.\"\"\"\n",
    "\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class OutputTemplateEvent(Event):\n",
    "    docs: List[Document]\n",
    "\n",
    "\n",
    "class QuestionsExtractedEvent(Event):\n",
    "    questions: List[str]\n",
    "\n",
    "\n",
    "class HandleQuestionEvent(Event):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class QuestionAnsweredEvent(Event):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class CollectedAnswersEvent(Event):\n",
    "    combined_answers: str\n",
    "\n",
    "\n",
    "class LogEvent(Event):\n",
    "    msg: str\n",
    "    delta: bool = False\n",
    "    # clear_previous: bool = False\n",
    "\n",
    "\n",
    "class RFPWorkflow(Workflow):\n",
    "    \"\"\"RFP workflow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools,\n",
    "        parser: LlamaParse,\n",
    "        llm: LLM | None = None,\n",
    "        similarity_top_k: int = 20,\n",
    "        output_dir: str = data_out_dir,\n",
    "        agent_system_prompt: str = AGENT_SYSTEM_PROMPT,\n",
    "        generate_output_prompt: str = GENERATE_OUTPUT_PROMPT,\n",
    "        extract_keys_prompt: str = EXTRACT_KEYS_PROMPT,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.tools = tools\n",
    "\n",
    "        self.parser = parser\n",
    "\n",
    "        self.llm = llm or OpenAI(model=\"gpt-4o-mini\")\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.agent_system_prompt = agent_system_prompt\n",
    "        self.extract_keys_prompt = extract_keys_prompt\n",
    "\n",
    "        # if not exists, create\n",
    "        out_path = Path(self.output_dir) / \"workflow_output\"\n",
    "        if not out_path.exists():\n",
    "            out_path.mkdir(parents=True, exist_ok=True)\n",
    "            os.chmod(str(out_path), 0o0777)\n",
    "\n",
    "        self.generate_output_prompt = PromptTemplate(generate_output_prompt)\n",
    "\n",
    "    @step\n",
    "    async def parse_output_template(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> OutputTemplateEvent:\n",
    "        # load output template file\n",
    "        out_template_path = Path(\n",
    "            f\"{self.output_dir}/workflow_output/output_template.jsonl\"\n",
    "        )\n",
    "        if out_template_path.exists():\n",
    "            with open(out_template_path, \"r\") as f:\n",
    "                docs = [Document.model_validate_json(line) for line in f]\n",
    "        else:\n",
    "            docs = await self.parser.aload_data(ev.rfp_template_path)\n",
    "            # save output template to file\n",
    "            with open(out_template_path, \"w\") as f:\n",
    "                for doc in docs:\n",
    "                    f.write(doc.model_dump_json())\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "        await ctx.set(\"output_template\", docs)\n",
    "        return OutputTemplateEvent(docs=docs)\n",
    "\n",
    "    @step\n",
    "    async def extract_questions(\n",
    "        self, ctx: Context, ev: OutputTemplateEvent\n",
    "    ) -> HandleQuestionEvent:\n",
    "        docs = ev.docs\n",
    "\n",
    "        # save all_questions to file\n",
    "        out_keys_path = Path(f\"{self.output_dir}/workflow_output/all_keys.txt\")\n",
    "        if out_keys_path.exists():\n",
    "            with open(out_keys_path, \"r\") as f:\n",
    "                output_qs = [q.strip() for q in f.readlines()]\n",
    "        else:\n",
    "            # try stuffing all text into the prompt\n",
    "            all_text = \"\\n\\n\".join([d.get_content(metadata_mode=\"all\") for d in docs])\n",
    "            prompt = PromptTemplate(template=self.extract_keys_prompt)\n",
    "\n",
    "            file_metadata = \"\\n\\n\".join([f\"Name:{t.metadata.name}\\nDescription:{t.metadata.description}\" for t in tools])\n",
    "            try:\n",
    "                if self._verbose:\n",
    "                    ctx.write_event_to_stream(LogEvent(msg=\">> Extracting questions from LLM\"))\n",
    "                \n",
    "                output_qs = self.llm.structured_predict(\n",
    "                    OutputQuestions, \n",
    "                    prompt, \n",
    "                    file_metadata=file_metadata,\n",
    "                    rfp_text=all_text,\n",
    "                ).questions\n",
    "\n",
    "                if self._verbose:\n",
    "                    qs_text = \"\\n\".join([f\"* {q}\" for q in output_qs])\n",
    "                    ctx.write_event_to_stream(LogEvent(msg=f\">> Questions:\\n{qs_text}\"))\n",
    "            \n",
    "            except Exception as e:\n",
    "                _logger.error(f\"Error extracting questions from page: {all_text}\")\n",
    "                _logger.error(e)\n",
    "\n",
    "            with open(out_keys_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(output_qs))\n",
    "\n",
    "        await ctx.set(\"num_to_collect\", len(output_qs))\n",
    "\n",
    "        for question in output_qs:\n",
    "            ctx.send_event(HandleQuestionEvent(question=question))\n",
    "\n",
    "        return None\n",
    "\n",
    "    @step\n",
    "    async def handle_question(\n",
    "        self, ctx: Context, ev: HandleQuestionEvent\n",
    "    ) -> QuestionAnsweredEvent:\n",
    "        question = ev.question\n",
    "\n",
    "        # initialize a Function Calling \"research\" agent where given a task, it can pull responses from relevant tools and synthesize over it\n",
    "        research_agent = FunctionCallingAgentWorker.from_tools(\n",
    "            tools, llm=llm, verbose=False, system_prompt=self.agent_system_prompt\n",
    "        ).as_agent()\n",
    "\n",
    "        # ensure the agent's memory is cleared\n",
    "        response = await research_agent.aquery(question)\n",
    "\n",
    "        if self._verbose:\n",
    "            # instead of printing the message directly, write the event to stream!\n",
    "            msg = f\">> Asked question: {question}\\n>> Got response: {str(response)}\"\n",
    "            ctx.write_event_to_stream(LogEvent(msg=msg))\n",
    "\n",
    "        return QuestionAnsweredEvent(question=question, answer=str(response))\n",
    "\n",
    "    @step\n",
    "    async def combine_answers(\n",
    "        self, ctx: Context, ev: QuestionAnsweredEvent\n",
    "    ) -> CollectedAnswersEvent:\n",
    "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
    "        results = ctx.collect_events(ev, [QuestionAnsweredEvent] * num_to_collect)\n",
    "        if results is None:\n",
    "            return None\n",
    "\n",
    "        combined_answers = \"\\n\".join([result.model_dump_json() for result in results])\n",
    "        # save combined_answers to file\n",
    "        with open(\n",
    "            f\"{self.output_dir}/workflow_output/combined_answers.jsonl\", \"w\"\n",
    "        ) as f:\n",
    "            f.write(combined_answers)\n",
    "\n",
    "        return CollectedAnswersEvent(combined_answers=combined_answers)\n",
    "\n",
    "    @step\n",
    "    async def generate_output(\n",
    "        self, ctx: Context, ev: CollectedAnswersEvent\n",
    "    ) -> StopEvent:\n",
    "        output_template = await ctx.get(\"output_template\")\n",
    "        output_template = \"\\n\".join(\n",
    "            [doc.get_content(\"none\") for doc in output_template]\n",
    "        )\n",
    "\n",
    "        if self._verbose:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=\">> GENERATING FINAL OUTPUT\"))\n",
    "\n",
    "        resp = await self.llm.astream(\n",
    "            self.generate_output_prompt,\n",
    "            output_template=output_template,\n",
    "            answers=ev.combined_answers,\n",
    "        )\n",
    "\n",
    "        final_output = \"\"\n",
    "        async for r in resp:\n",
    "            ctx.write_event_to_stream(LogEvent(msg=r, delta=True))\n",
    "            final_output += r\n",
    "\n",
    "        # save final_output to file\n",
    "        with open(f\"{self.output_dir}/workflow_output/final_output.md\", \"w\") as f:\n",
    "            f.write(final_output)\n",
    "\n",
    "        return StopEvent(result=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b895c3b1-6ea1-41c3-bcf9-e42c2a4beb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "workflow = RFPWorkflow(\n",
    "    tools,\n",
    "    parser=parser,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    timeout=None,  # don't worry about timeout to make sure it completes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb19c4-9133-4a3f-b0bd-adf14399e21b",
   "metadata": {},
   "source": [
    "#### Visualize the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa35ed08-edc1-4bd3-b80d-6e745367128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfp_workflow.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(RFPWorkflow, filename=\"rfp_workflow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2effc-350a-46e6-b325-45c1b24b6e89",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Let's run the full workflow and generate the output! \n",
    "\n",
    "This will take 5-20 minutes to run and complete. You can inspect the intermediate verbose outputs below as the intermediate questions/answers are generated. The response is streamed back to the user at the end - the response itself is quite long so will take a while to complete! You can also integrate with an observability provider like LlamaTrace/Arize Phoenix in order to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c7db55-aff9-4d20-aa13-4e0931b39f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_output_template\n",
      "Started parsing the file under job_id 7d9930d7-a038-4ee6-a22d-d3d585dfc8fd\n",
      "Step parse_output_template produced event OutputTemplateEvent\n",
      "Running step extract_questions\n",
      "Step extract_questions produced no event\n",
      "Running step handle_question\n",
      ">> Extracting questions from LLM\n",
      ">> Questions: * What is the proposed approach for achieving secure data transfer using a Transfer Cross Domain Solution consistent with the 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements?\n",
      "* How will the proposed Transfer Cross Domain Solution address secure one-way data transfer between logical enclaves within JEDI Cloud, to external destinations, and across classification levels?\n",
      "* What is the proposed logical isolation architecture and implementation for unclassified and classified offerings, specifically regarding encryption of data at rest and in transit?\n",
      "* How does the proposed solution ensure logical separation with cryptographic certainty of processing between tenants within the virtualized environment?\n",
      "* What is the proposed approach to meeting the requirements for classified processing at different classification levels, and how does it address logical separation between Secret and Top Secret?\n",
      "* How does the proposed tactical edge solution balance portability with capability across the range of military operations?\n",
      "* What are the characteristics and capabilities of the proposed Category One tactical edge device, including ruggedization, power requirements, and rapid deployment features?\n",
      "* What are the characteristics and capabilities of the proposed Category Two tactical edge device, including rapid production and deployment features?\n",
      "* What is the proposed information security approach, specifically regarding patching and vulnerability management, supply chain risk management, and breach identification and mitigation?\n",
      "* How does the proposed solution manage access controls, including technical policies, role-based access control, and federated authentication?\n",
      "* What is the proposed approach to application and data hosting, including rapid provisioning and container-based application hosting?\n",
      "* How does the proposed solution ensure application and data portability, including exporting data and system configurations?\n",
      "* What is the proposed program management approach for managing the JEDI Cloud contract, including risk management and quality assurance?\n",
      "* How does the proposed solution support small business participation, and what are the proposed goals and commitments for small business involvement?\n",
      "* What is the proposed approach for the Commercial Cloud Offering Marketplace, including ease of use and deployment of third-party services?\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Running step handle_question\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How will the proposed Transfer Cross Domain Solution address secure one-way data transfer between logical enclaves within JEDI Cloud, to external destinations, and across classification levels?\n",
      ">> Got response: The document does not provide specific details about the proposed Transfer Cross Domain Solution for secure one-way data transfer within JEDI Cloud. It primarily focuses on Microsoft Azure Government's secure and compliant cloud services for U.S. government entities, emphasizing trust, privacy, and innovation. For detailed information on the Transfer Cross Domain Solution, additional resources or specific documentation related to JEDI Cloud would be required.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the proposed solution ensure logical separation with cryptographic certainty of processing between tenants within the virtualized environment?\n",
      ">> Got response: The proposed solution ensures logical separation with cryptographic certainty of processing between tenants within the virtualized environment by leveraging Azure Government's secure and compliant cloud services. Azure Government provides a dedicated physical instance of Microsoft Azure with a dedicated network, ensuring physical and logical separation. This setup is complemented by compliance with standards such as FedRAMP and CJIS, which include cryptographic measures to ensure data integrity and confidentiality between tenants.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the proposed logical isolation architecture and implementation for unclassified and classified offerings, specifically regarding encryption of data at rest and in transit?\n",
      ">> Got response: The proposed logical isolation architecture and implementation for unclassified and classified offerings in Microsoft Azure Government involves providing a physically isolated instance of Microsoft Azure. This architecture employs world-class security and compliance services critical to U.S. government systems and applications. \n",
      "\n",
      "Regarding encryption, Azure Government ensures the encryption of data both at rest and in transit. This is part of its commitment to security, privacy, and compliance, which are foundational principles of the platform. The platform is designed to meet stringent U.S. government requirements, including compliance with standards such as FedRAMP High and CJIS for federal law enforcement data.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the proposed approach for achieving secure data transfer using a Transfer Cross Domain Solution consistent with the 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements?\n",
      ">> Got response: The document \"azure_gov.pdf\" does not provide specific details on the proposed approach for achieving secure data transfer using a Transfer Cross Domain Solution consistent with the 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements. It primarily focuses on Microsoft Azure Government's secure and compliant cloud services tailored for U.S. government entities, emphasizing compliance standards and security measures.\n",
      "\n",
      "For detailed information on the specific approach to secure data transfer using a Transfer Cross Domain Solution, it would be best to consult the original 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements document or related technical documentation from authoritative sources on cross-domain solutions.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the characteristics and capabilities of the proposed Category One tactical edge device, including ruggedization, power requirements, and rapid deployment features?\n",
      ">> Got response: The document does not provide specific details about the characteristics and capabilities of the proposed Category One tactical edge device, including ruggedization, power requirements, and rapid deployment features. It primarily focuses on Microsoft Azure Government's secure and compliant cloud services for U.S. government entities. For detailed information on the tactical edge device, additional sources or documents specifically addressing this device would be needed.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the proposed tactical edge solution balance portability with capability across the range of military operations?\n",
      ">> Got response: The proposed tactical edge solution balances portability with capability across the range of military operations by leveraging Microsoft Azure Government's secure and compliant cloud services. These services are tailored for U.S. government entities, ensuring that they meet stringent compliance standards while providing robust capabilities. The solution emphasizes digital transformation and cloud service models that support a wide range of operations, ensuring that military operations can be conducted efficiently and securely, regardless of location. This balance is achieved through a combination of secure network, storage, and compute services, along with advanced analytics and IoT capabilities, which together provide a flexible and powerful platform for military needs.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What are the characteristics and capabilities of the proposed Category Two tactical edge device, including rapid production and deployment features?\n",
      ">> Got response: The document does not provide specific details about the characteristics and capabilities of the proposed Category Two tactical edge device, including rapid production and deployment features. It primarily focuses on Microsoft Azure Government's secure and compliant cloud services for U.S. government entities, digital transformation, cloud service models, and compliance standards. If you have more specific questions or need information from another document, please let me know!\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the proposed approach to meeting the requirements for classified processing at different classification levels, and how does it address logical separation between Secret and Top Secret?\n",
      ">> Got response: The document does not provide specific details on the proposed approach to meeting the requirements for classified processing at different classification levels, nor does it address the logical separation between Secret and Top Secret classifications. The document primarily focuses on Microsoft Azure Government's compliance standards, secure cloud services, and its commitment to supporting U.S. government operations. For detailed information on classified processing and logical separation, it might be necessary to consult specific security guidelines or policies related to Azure Government or contact Microsoft directly for more precise information.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: What is the proposed information security approach, specifically regarding patching and vulnerability management, supply chain risk management, and breach identification and mitigation?\n",
      ">> Got response: The proposed information security approach regarding patching, vulnerability management, supply chain risk management, and breach identification and mitigation includes several key strategies:\n",
      "\n",
      "1. **Patching and Vulnerability Management**:\n",
      "   - A significant portion of IoT devices on customer networks have known vulnerabilities, with 46% being unpatchable. This highlights the need for a comprehensive defense strategy that covers the entire business ecosystem, especially the intersection of information technology and operational technology (IT-OT).\n",
      "   - The discovery of new zero-day vulnerabilities in critical systems like the CODESYS runtime emphasizes the importance of addressing supply chain vulnerabilities to secure critical infrastructure.\n",
      "\n",
      "2. **Supply Chain Risk Management**:\n",
      "   - Collaboration among leading technology companies, such as Microsoft, Google, Amazon, and IBM, is crucial for advancing open-source security and fighting cybercrime. This collaboration is essential for constructing and maintaining the digital infrastructure that underpins society.\n",
      "   - The establishment of the Open Source Security Foundation (OpenSSF) by Microsoft and Google aims to solve current and emerging challenges in supply chain security. This includes frameworks like the Supply Chain Levels for Software Artifacts (SLSA) and the Secure Supply Chain Consumption Framework (S2C2F), which provide end-to-end tools for engineers to address threat landscapes with scalable mitigation techniques.\n",
      "\n",
      "3. **Breach Identification and Mitigation**:\n",
      "   - The \"Assume Breach\" strategy involves Red Teams simulating real-world attacks and Blue Teams focusing on detecting, protecting, and recovering from threats. This approach helps in identifying attacks and restoring environments effectively.\n",
      "   - A Return on Mitigation (ROM) framework is used to prioritize security investments based on their effectiveness and ease of implementation. This framework helps in making environments more resilient to cyberattacks by focusing on high-return mitigations like context-based MFA protection.\n",
      "\n",
      "These strategies emphasize the importance of collaboration, comprehensive defense, and prioritization of security measures to enhance cybersecurity resilience.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the proposed solution manage access controls, including technical policies, role-based access control, and federated authentication?\n",
      ">> Got response: The proposed solution for managing access controls in Microsoft Azure, including technical policies, role-based access control (RBAC), and federated authentication, is detailed as follows:\n",
      "\n",
      "1. **Technical Policies**: Microsoft Azure provides a comprehensive set of compliance standards and security policies tailored for U.S. government entities through Azure Government. This includes adherence to the Criminal Justice Information Services (CJIS) Security Policy, which involves auditing and compliance checks to ensure that all security requirements are met. Azure Government emphasizes compliance with FedRAMP and other regulatory standards to ensure secure cloud operations.\n",
      "\n",
      "2. **Role-Based Access Control (RBAC)**: Azure implements RBAC to manage access to resources. This allows administrators to assign roles to users, groups, and applications, granting them only the permissions they need to perform their tasks. This minimizes the risk of unauthorized access and enhances security by adhering to the principle of least privilege.\n",
      "\n",
      "3. **Federated Authentication**: Azure supports federated authentication, enabling seamless integration with existing identity systems. This allows users to authenticate using their organizational credentials, facilitating single sign-on (SSO) and reducing the need for multiple passwords. Azure Active Directory (Azure AD) plays a crucial role in managing identities and access, supporting various authentication protocols and providing a secure identity platform.\n",
      "\n",
      "Overall, Microsoft Azure's approach to access control is designed to provide secure, compliant, and efficient management of resources, ensuring that only authorized users have access to the necessary data and applications.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      "Running step handle_question\n",
      ">> Asked question: How does the proposed solution ensure application and data portability, including exporting data and system configurations?\n",
      ">> Got response: The proposed solution for ensuring application and data portability, including exporting data and system configurations, involves several key features and strategies:\n",
      "\n",
      "1. **Open and Hybrid Cloud Solutions**: Microsoft Azure supports open source solutions and allows for the extension of on-premises identity, applications, and data. This flexibility enables organizations to build and run applications in a way that suits their specific needs, whether on-premises or in the cloud.\n",
      "\n",
      "2. **Deployment Flexibility**: Azure provides the capability to deploy cloud services on-premises, which supports hybrid cloud models. This ensures that applications and data can be moved and managed across different environments without being locked into a single vendor or infrastructure.\n",
      "\n",
      "3. **Compliance and Security**: Azure Government, specifically tailored for U.S. government entities, emphasizes compliance with standards like FedRAMP and CJIS. This ensures that data and applications can be securely managed and transferred in compliance with regulatory requirements.\n",
      "\n",
      "4. **Data Export and System Configuration**: Azure offers tools and services that facilitate the export of data and system configurations. This includes services like Azure Backup and Azure Site Recovery, which help in maintaining data integrity and availability across different environments.\n",
      "\n",
      "5. **Geo-Replication and Dedicated Networks**: Azure Government provides geo-replication between locations and a dedicated physical network, which enhances data portability and ensures that applications can be consistently accessed and managed across different regions.\n",
      "\n",
      "These features collectively ensure that applications and data can be ported across different environments, maintaining flexibility, compliance, and security.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What is the proposed approach to application and data hosting, including rapid provisioning and container-based application hosting?\n",
      ">> Got response: I am currently unable to retrieve the information from the documents due to repeated errors. However, I can provide a general overview based on common practices in cloud computing.\n",
      "\n",
      "In cloud environments like Microsoft Azure, the approach to application and data hosting often includes:\n",
      "\n",
      "1. **Rapid Provisioning**: This involves quickly setting up and deploying resources as needed. Cloud platforms provide tools and services that allow for the automated provisioning of resources, reducing the time and effort required to set up infrastructure.\n",
      "\n",
      "2. **Container-Based Application Hosting**: Containers are a lightweight form of virtualization that allows applications to run in isolated environments. They are portable and can be deployed consistently across different environments. Azure offers services like Azure Kubernetes Service (AKS) for managing containerized applications.\n",
      "\n",
      "These approaches help in achieving scalability, flexibility, and efficiency in managing applications and data in the cloud. If you need more specific information, I recommend trying to access the documents again later or contacting support for assistance.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What is the proposed approach for the Commercial Cloud Offering Marketplace, including ease of use and deployment of third-party services?\n",
      ">> Got response: The proposed approach for the Commercial Cloud Offering Marketplace emphasizes ease of use and deployment of third-party services. Microsoft aims to provide a platform that facilitates the integration and deployment of third-party services, enhancing the overall user experience. This approach involves creating a robust and reliable infrastructure that supports the growth and augmentation of existing services, such as Azure, Microsoft 365, and Dynamics 365, among others. The focus is on maintaining a seamless and efficient environment for third-party services to operate, ensuring that users can easily access and deploy these services within the Microsoft ecosystem.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: What is the proposed program management approach for managing the JEDI Cloud contract, including risk management and quality assurance?\n",
      ">> Got response: I am currently unable to retrieve the information from the document due to a technical issue. However, I can provide some general insights based on typical practices for managing large cloud contracts like JEDI.\n",
      "\n",
      "For managing a cloud contract such as JEDI, the program management approach would likely include:\n",
      "\n",
      "1. **Risk Management**: This involves identifying potential risks early in the project and developing strategies to mitigate them. This could include regular risk assessments, maintaining a risk register, and having contingency plans in place.\n",
      "\n",
      "2. **Quality Assurance**: Ensuring that the services provided meet the required standards and specifications. This could involve regular audits, performance monitoring, and feedback loops to ensure continuous improvement.\n",
      "\n",
      "3. **Governance Framework**: Establishing a clear governance structure to oversee the project, including roles and responsibilities, decision-making processes, and reporting mechanisms.\n",
      "\n",
      "4. **Stakeholder Engagement**: Regular communication with all stakeholders to ensure alignment and address any concerns promptly.\n",
      "\n",
      "5. **Performance Metrics**: Defining key performance indicators (KPIs) to measure the success of the project and ensure it meets its objectives.\n",
      "\n",
      "For specific details on the JEDI Cloud contract, I recommend checking the official documentation or announcements from the Department of Defense or Microsoft. If you have any other questions or need further assistance, feel free to ask!\n",
      "Running step combine_answers\n",
      "Step combine_answers produced no event\n",
      "Step handle_question produced event QuestionAnsweredEvent\n",
      ">> Asked question: How does the proposed solution support small business participation, and what are the proposed goals and commitments for small business involvement?\n",
      ">> Got response: I am currently unable to retrieve the information from the documents due to a technical issue. However, I can provide some general insights based on typical practices:\n",
      "\n",
      "1. **Support for Small Business Participation**: Solutions often support small business participation by providing access to resources, training, and platforms that enable them to compete on a level playing field with larger enterprises. This can include cloud services, cybersecurity tools, and business applications tailored to small business needs.\n",
      "\n",
      "2. **Proposed Goals and Commitments**: Goals and commitments for small business involvement typically include increasing the percentage of contracts awarded to small businesses, providing mentorship and partnership opportunities, and ensuring that small businesses have access to the latest technology and innovations.\n",
      "\n",
      "If you need specific details from the documents, I recommend trying again later or contacting support for assistance.\n",
      "Running step combine_answers\n",
      "Step combine_answers produced event CollectedAnswersEvent\n",
      "Running step generate_output\n",
      ">> GENERATING FINAL OUTPUT\n",
      "# Proposal Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Our proposal for the JEDI Cloud RFP # HQ0034-18-R-0077 outlines a comprehensive approach to delivering secure, scalable, and efficient cloud services tailored to the needs of the Department of Defense (DoD). Leveraging Microsoft Azure Government's robust infrastructure, we ensure compliance with stringent security standards while providing innovative solutions for data management, application hosting, and tactical edge capabilities.\n",
      "\n",
      "## Technical Approach\n",
      "\n",
      "### Secure Data Transfer and Logical Isolation\n",
      "\n",
      "**Transfer Cross Domain Solution**: Our approach to secure data transfer involves leveraging Microsoft Azure Government's secure cloud services, which are compliant with the 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements. This ensures secure one-way data transfer between logical enclaves within JEDI Cloud, to external destinations, and across classification levels.\n",
      "\n",
      "**Logical Separation**: We ensure logical separation with cryptographic certainty of processing between tenants within the virtualized environment by utilizing Azure Government's dedicated physical instance and network, ensuring both physical and logical separation.\n",
      "\n",
      "**Encryption**: Our solution provides encryption of data at rest and in transit, adhering to NSA-approved algorithms and procedures specified in CNSSP 15.\n",
      "\n",
      "### Tactical Edge Capabilities\n",
      "\n",
      "**Category One Device**: Our proposed Category One tactical edge device is ruggedized, portable, and capable of operating in both connected and disconnected environments. It features industry-standard connectors, battery and generator power options, and rapid deployment capabilities.\n",
      "\n",
      "**Category Two Device**: The Category Two device is a modular, rapidly deployable data center that can be connected to government-provided power and networking. It is designed for deployment on U.S. soil OCONUS or on government-owned platforms.\n",
      "\n",
      "**Portability and Capability**: Our tactical edge solution balances portability with capability, ensuring robust performance across the range of military operations.\n",
      "\n",
      "### Information Security and Access Controls\n",
      "\n",
      "**Patching and Vulnerability Management**: We employ a comprehensive strategy for patching and vulnerability management, addressing supply chain risks and ensuring timely breach identification and mitigation.\n",
      "\n",
      "**Access Controls**: Our solution includes robust role-based access control (RBAC) and federated authentication, ensuring secure and efficient management of resources.\n",
      "\n",
      "### Application and Data Hosting and Portability\n",
      "\n",
      "**Rapid Provisioning**: We offer rapid provisioning of virtual machines and container-based application hosting, supported by Azure Kubernetes Service (AKS).\n",
      "\n",
      "**Data Portability**: Our solution ensures seamless application and data portability, with tools for exporting data and system configurations across different environments.\n",
      "\n",
      "### Commercial Cloud Offering Marketplace\n",
      "\n",
      "**Ease of Use**: Our Commercial Cloud Offering Marketplace is designed for ease of use, facilitating the deployment of third-party services and enhancing user experience.\n",
      "\n",
      "## Program Management Approach\n",
      "\n",
      "**Risk Management**: We implement a proactive risk management strategy, identifying potential risks early and developing mitigation plans.\n",
      "\n",
      "**Quality Assurance**: Our quality assurance processes ensure that services meet required standards and specifications, with regular audits and performance monitoring.\n",
      "\n",
      "## Small Business Participation\n",
      "\n",
      "**Goals and Commitments**: We are committed to maximizing small business participation, proposing substantive goals and commitments to involve small businesses in the performance of CLINs x003.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Our proposal for the JEDI Cloud RFP # HQ0034-18-R-0077 demonstrates our capability to deliver secure, compliant, and innovative cloud solutions tailored to the needs of the DoD. We are committed to providing exceptional service and support, ensuring the success of the JEDI Cloud initiative.Step generate_output produced event StopEvent\n",
      "# Proposal Response to JEDI Cloud RFP # HQ0034-18-R-0077\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "Our proposal for the JEDI Cloud RFP # HQ0034-18-R-0077 outlines a comprehensive approach to delivering secure, scalable, and efficient cloud services tailored to the needs of the Department of Defense (DoD). Leveraging Microsoft Azure Government's robust infrastructure, we ensure compliance with stringent security standards while providing innovative solutions for data management, application hosting, and tactical edge capabilities.\n",
      "\n",
      "## Technical Approach\n",
      "\n",
      "### Secure Data Transfer and Logical Isolation\n",
      "\n",
      "**Transfer Cross Domain Solution**: Our approach to secure data transfer involves leveraging Microsoft Azure Government's secure cloud services, which are compliant with the 2018 Raise the Bar Cross Domain Solution Design and Implementation Requirements. This ensures secure one-way data transfer between logical enclaves within JEDI Cloud, to external destinations, and across classification levels.\n",
      "\n",
      "**Logical Separation**: We ensure logical separation with cryptographic certainty of processing between tenants within the virtualized environment by utilizing Azure Government's dedicated physical instance and network, ensuring both physical and logical separation.\n",
      "\n",
      "**Encryption**: Our solution provides encryption of data at rest and in transit, adhering to NSA-approved algorithms and procedures specified in CNSSP 15.\n",
      "\n",
      "### Tactical Edge Capabilities\n",
      "\n",
      "**Category One Device**: Our proposed Category One tactical edge device is ruggedized, portable, and capable of operating in both connected and disconnected environments. It features industry-standard connectors, battery and generator power options, and rapid deployment capabilities.\n",
      "\n",
      "**Category Two Device**: The Category Two device is a modular, rapidly deployable data center that can be connected to government-provided power and networking. It is designed for deployment on U.S. soil OCONUS or on government-owned platforms.\n",
      "\n",
      "**Portability and Capability**: Our tactical edge solution balances portability with capability, ensuring robust performance across the range of military operations.\n",
      "\n",
      "### Information Security and Access Controls\n",
      "\n",
      "**Patching and Vulnerability Management**: We employ a comprehensive strategy for patching and vulnerability management, addressing supply chain risks and ensuring timely breach identification and mitigation.\n",
      "\n",
      "**Access Controls**: Our solution includes robust role-based access control (RBAC) and federated authentication, ensuring secure and efficient management of resources.\n",
      "\n",
      "### Application and Data Hosting and Portability\n",
      "\n",
      "**Rapid Provisioning**: We offer rapid provisioning of virtual machines and container-based application hosting, supported by Azure Kubernetes Service (AKS).\n",
      "\n",
      "**Data Portability**: Our solution ensures seamless application and data portability, with tools for exporting data and system configurations across different environments.\n",
      "\n",
      "### Commercial Cloud Offering Marketplace\n",
      "\n",
      "**Ease of Use**: Our Commercial Cloud Offering Marketplace is designed for ease of use, facilitating the deployment of third-party services and enhancing user experience.\n",
      "\n",
      "## Program Management Approach\n",
      "\n",
      "**Risk Management**: We implement a proactive risk management strategy, identifying potential risks early and developing mitigation plans.\n",
      "\n",
      "**Quality Assurance**: Our quality assurance processes ensure that services meet required standards and specifications, with regular audits and performance monitoring.\n",
      "\n",
      "## Small Business Participation\n",
      "\n",
      "**Goals and Commitments**: We are committed to maximizing small business participation, proposing substantive goals and commitments to involve small businesses in the performance of CLINs x003.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Our proposal for the JEDI Cloud RFP # HQ0034-18-R-0077 demonstrates our capability to deliver secure, compliant, and innovative cloud solutions tailored to the needs of the DoD. We are committed to providing exceptional service and support, ensuring the success of the JEDI Cloud initiative.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "handler = workflow.run(rfp_template_path=\"data/jedi_cloud_rfp.pdf\")\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, LogEvent):\n",
    "\n",
    "        if event.delta:\n",
    "            print(event.msg, end=\"\")\n",
    "        else:\n",
    "            print(event.msg)\n",
    "\n",
    "response = await handler\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db69c96-721e-479a-b34a-9c093d58ca48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamacloud-demo",
   "language": "python",
   "name": "llamacloud-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
