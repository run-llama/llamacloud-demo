{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Report Generation\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llamacloud-demo/blob/main/examples/report_generation/report_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this notebook we show you how to perform financial report generation with LlamaCloud consisting of text and tables, given an existing bank of reports.\n",
    "\n",
    "LlamaCloud provides advanced retrieval endpoints allowing you to fetch chunk and document-level context from complex financial reports consisting of text, tables, and sometimes images/diagrams.\n",
    "\n",
    "We build an agentic workflow on top of LlamaCloud consisting of researcher and writer steps in order to generate the final response.\n",
    "\n",
    "![](financial_report_generation_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install core packages, download 10k files from Apple and Tesla.\n",
    "\n",
    "You will need to upload these documents to LlamaCloud. For best results, we recommend: \n",
    "- Setting Parse settings to \"Accurate\" mode, \"Premium\" mode, or \"3rd Party multimodal\" \n",
    "- Setting the \"Segmentation Configuration\" to \"Page\" and the \"Chunking Configuration\" to None. This will give you page-level chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-core\n",
    "!pip install llama-index-embeddings-openai\n",
    "!pip install llama-index-question-gen-openai\n",
    "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
    "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
    "!pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "# download Apple \n",
    "!wget \"https://s2.q4cdn.com/470004039/files/doc_earnings/2023/q4/filing/_10-K-Q4-2023-As-Filed.pdf\" -O data/apple_2023.pdf\n",
    "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2022/q4/_10-K-2022-(As-Filed).pdf\" -O data/apple_2022.pdf\n",
    "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2021/q4/_10-K-2021-(As-Filed).pdf\" -O data/apple_2021.pdf\n",
    "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2020/ar/_10-K-2020-(As-Filed).pdf\" -O data/apple_2020.pdf\n",
    "!wget \"https://www.dropbox.com/scl/fi/i6vk884ggtq382mu3whfz/apple_2019_10k.pdf?rlkey=eudxh3muxh7kop43ov4bgaj5i&dl=1\" -O data/apple_2019.pdf\n",
    "\n",
    "# download Tesla\n",
    "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\" -O data/tesla_2023.pdf\n",
    "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000095017023001409/tsla-20221231-gen.pdf\" -O data/tesla_2022.pdf\n",
    "!wget \"https://www.dropbox.com/scl/fi/ptk83fmye7lqr7pz9r6dm/tesla_2021_10k.pdf?rlkey=24kxixeajbw9nru1sd6tg3bye&dl=1\" -O data/tesla_2021.pdf\n",
    "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000156459021004599/tsla-10k_20201231-gen.pdf\" -O data/tesla_2020.pdf\n",
    "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000156459020004475/tsla-10k_20191231-gen_0.pdf\" -O data/tesla_2019.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the tokenizer to be gpt-4o specific. Some of our workflows involving cramming as much context into the prompt, and to make this work robustly without context overflow errors, we will want to make sure our tokenizer is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import set_global_tokenizer\n",
    "import tiktoken\n",
    "\n",
    "set_global_tokenizer(tiktoken.encoding_for_model(\"gpt-4o\").encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# API access to llama-cloud\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenAI API for embeddings/llms\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup embedding/LLM model\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Documents into LlamaCloud\n",
    "\n",
    "The first order of business is to download the 5 Apple and Tesla 10Ks and upload them into LlamaCloud.\n",
    "\n",
    "You can easily do this by creating a pipeline and uploading docs via the \"Files\" mode.\n",
    "\n",
    "After this is done, proceed to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LlamaCloud File/Chunk Retriever over Documents\n",
    "\n",
    "In this section we define both a file-level and chunk-level LlamaCloud Retriever over these documents.\n",
    "\n",
    "The file-level LlamaCloud retriever returns entire documents with a `files_top_k`. There are two retrieval modes:\n",
    "- `files_via_content`: Retrieve top-k chunks, dereference into source files. Use a weighted average heuristic to determine the top files to return.\n",
    "- `files_via_metadata`: Use an LLM to analyze the metadata of each file, and determine the top files that are most relevant to the query.\n",
    "\n",
    "The chunk-level LlamaCloud retriever is our default retriever that returns chunks via hybrid search + reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "import os\n",
    "\n",
    "index = LlamaCloudIndex(\n",
    "  name=\"apple_tesla_demo_2\",\n",
    "  project_name=\"llamacloud_demo\",\n",
    "  api_key=os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define File Retriever\n",
    "\n",
    "In this section we define the file-level retriever. By default we use `retrieval_mode=\"files_via_content\"`, but you can also change it to `files_via_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_retriever = index.as_retriever(\n",
    "    retrieval_mode=\"files_via_content\",\n",
    "    files_top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = doc_retriever.retrieve(\"Give me a summary of Tesla in 2019\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define chunk retriever\n",
    "\n",
    "The chunk-level retriever does vector search with a final reranked set of `rerank_top_n=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_retriever = index.as_retriever(\n",
    "    retrieval_mode=\"chunks\",\n",
    "    rerank_top_n=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Retriever Tools\n",
    "\n",
    "Wrap these with Python functions into tool objects - these will directly be used by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import List\n",
    "\n",
    "# function tools\n",
    "def chunk_retriever_fn(query: str) -> List[NodeWithScore]:\n",
    "    \"\"\"Retrieves a small set of relevant document chunks from the corpus.\n",
    "\n",
    "    ONLY use for research questions that want to look up specific facts from the knowledge corpus,\n",
    "    and don't need entire documents.\n",
    "\n",
    "    \"\"\"\n",
    "    return chunk_retriever.retrieve(query)\n",
    "\n",
    "def doc_retriever_fn(query: str) -> float:\n",
    "    \"\"\"Document retriever that retrieves entire documents from the corpus.\n",
    "\n",
    "    ONLY use for research questions that may require searching over entire research reports.\n",
    "\n",
    "    Will be slower and more expensive than chunk-level retrieval but may be necessary.\n",
    "    \"\"\"\n",
    "    return doc_retriever.retrieve(query)\n",
    "\n",
    "chunk_retriever_tool = FunctionTool.from_defaults(fn=chunk_retriever_fn)\n",
    "doc_retriever_tool = FunctionTool.from_defaults(fn=doc_retriever_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Report Generation Workflow\n",
    "\n",
    "Now that we've defined the retrievers, we're ready to build the report generation workflow.\n",
    "\n",
    "The workflow contains roughly the following steps:\n",
    "\n",
    "1. **Research Gathering**: Perform a function calling loop where the agent tries to reason about what tool to call (chunk-level or document-level retrieval) in order to gather more information. All information is shared to a dictionary that is propagated throughout each step. The tools return an indication of the type of information returned to the agent. After the agent feels like it's gathered enough information, move on to the next phase.\n",
    "2. **Report Generation**: Generate a research report given the pooled research. For now, try to stuff as much information into the context window through the summary index.\n",
    "\n",
    "This implementation is inspired by our [Function Calling Agent](https://docs.llamaindex.ai/en/stable/examples/workflow/function_calling_agent/) workflow implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "class TextBlock(BaseModel):\n",
    "    \"\"\"Text block.\"\"\"\n",
    "\n",
    "    text: str = Field(..., description=\"The text for this block.\")\n",
    "\n",
    "\n",
    "class TableBlock(BaseModel):\n",
    "    \"\"\"Image block.\"\"\"\n",
    "\n",
    "    caption: str = Field(..., description=\"Caption of the table.\")\n",
    "    col_names: List[str] = Field(..., description=\"Names of the columns.\")\n",
    "    rows: List[Tuple] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of rows. Each row is a data entry tuple, \"\n",
    "            \"where each element of the tuple corresponds positionally to the column name.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def to_df(self) -> pd.DataFrame:\n",
    "        \"\"\"To dataframe.\"\"\"\n",
    "        df = pd.DataFrame(self.rows, columns=self.col_names)\n",
    "        df.style.set_caption(self.caption)\n",
    "        return df\n",
    "\n",
    "\n",
    "class ReportOutput(BaseModel):\n",
    "    \"\"\"Data model for a report.\n",
    "\n",
    "    Can contain a mix of text and table blocks. Use table blocks to present any quantitative metrics and comparisons.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    blocks: List[TextBlock | TableBlock] = Field(\n",
    "        ..., description=\"A list of text and table blocks.\"\n",
    "    )\n",
    "\n",
    "    def render(self) -> None:\n",
    "        \"\"\"Render as formatted text within a jupyter notebook.\"\"\"\n",
    "        for b in self.blocks:\n",
    "            if isinstance(b, TextBlock):\n",
    "                display(Markdown(b.text))\n",
    "            else:\n",
    "                display(b.to_df())\n",
    "\n",
    "\n",
    "report_gen_system_prompt = \"\"\"\\\n",
    "You are a report generation assistant tasked with producing a well-formatted report given parsed context.\n",
    "You will be given context from one or more reports that take the form of parsed text + tables\n",
    "You are responsible for producing a report with interleaving text and tables - in the format of interleaving text and \"table\" blocks.\n",
    "\n",
    "Make sure the report is detailed with a lot of textual explanations especially if tables are given.\n",
    "\n",
    "You MUST output your response as a tool call in order to adhere to the required output format. Do NOT give back normal text.\n",
    "\n",
    "Here is an example of a toy valid tool call - note the text and table block:\n",
    "```\n",
    "{\n",
    "    \"blocks\": [\n",
    "        {\n",
    "            \"text\": \"A report on cities\"\n",
    "        },\n",
    "        {\n",
    "            \"caption\": \"Comparison of CityA vs. CityB\",\n",
    "            \"col_names\": [\n",
    "              \"\",\n",
    "              \"Population\",\n",
    "              \"Country\",\n",
    "            ],\n",
    "            \"rows\": [\n",
    "              [\n",
    "                \"CityA\",\n",
    "                \"1,000,000\",\n",
    "                \"USA\"\n",
    "              ],\n",
    "              [\n",
    "                \"CityB\",\n",
    "                \"2,000,000\",\n",
    "                \"Mexico\"\n",
    "              ]\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "report_gen_llm = OpenAI(model=\"gpt-4o\", max_tokens=2048, system_prompt=report_gen_system_prompt)\n",
    "report_gen_sllm = report_gen_llm.as_structured_llm(output_cls=ReportOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import Workflow\n",
    "\n",
    "from typing import Any, List\n",
    "from operator import itemgetter\n",
    "\n",
    "from llama_index.core.llms.function_calling import FunctionCallingLLM\n",
    "from llama_index.core.llms.structured_llm import StructuredLLM\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools.types import BaseTool\n",
    "from llama_index.core.tools import ToolSelection\n",
    "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, Context, step\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import TreeSummarize, CompactAndRefine\n",
    "from llama_index.core.workflow import Event\n",
    "\n",
    "\n",
    "class InputEvent(Event):\n",
    "    input: List[ChatMessage]\n",
    "\n",
    "\n",
    "class ChunkRetrievalEvent(Event):\n",
    "    tool_call: ToolSelection\n",
    "\n",
    "\n",
    "class DocRetrievalEvent(Event):\n",
    "    tool_call: ToolSelection\n",
    "\n",
    "\n",
    "class ReportGenerationEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ReportGenerationAgent(Workflow):\n",
    "    \"\"\"Report generation agent.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chunk_retriever_tool: BaseTool,\n",
    "        doc_retriever_tool: BaseTool,\n",
    "        llm: FunctionCallingLLM | None = None,\n",
    "        report_gen_sllm: StructuredLLM | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.chunk_retriever_tool = chunk_retriever_tool\n",
    "        self.doc_retriever_tool = doc_retriever_tool\n",
    "\n",
    "        self.llm = llm or OpenAI()\n",
    "        self.summarizer = CompactAndRefine(llm=self.llm)\n",
    "        assert self.llm.metadata.is_function_calling_model\n",
    "\n",
    "        self.report_gen_sllm = report_gen_sllm or self.llm.as_structured_llm(\n",
    "            ReportOutput, system_prompt=report_gen_system_prompt\n",
    "        )\n",
    "        self.report_gen_summarizer = TreeSummarize(llm=self.report_gen_sllm)\n",
    "\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(llm=llm)\n",
    "        self.sources = []\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def prepare_chat_history(self, ctx: Context, ev: StartEvent) -> InputEvent:\n",
    "        # clear sources\n",
    "        self.sources = []\n",
    "\n",
    "        ctx.data[\"stored_chunks\"] = []\n",
    "        ctx.data[\"query\"] = ev.input\n",
    "\n",
    "        # get user input\n",
    "        user_input = ev.input\n",
    "        user_msg = ChatMessage(role=\"user\", content=user_input)\n",
    "        self.memory.put(user_msg)\n",
    "\n",
    "        # get chat history\n",
    "        chat_history = self.memory.get()\n",
    "        return InputEvent(input=chat_history)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def handle_llm_input(\n",
    "        self, ctx: Context, ev: InputEvent\n",
    "    ) -> ChunkRetrievalEvent | DocRetrievalEvent | ReportGenerationEvent | StopEvent:\n",
    "        chat_history = ev.input\n",
    "\n",
    "        response = await self.llm.achat_with_tools(\n",
    "            [self.chunk_retriever_tool, self.doc_retriever_tool],\n",
    "            chat_history=chat_history,\n",
    "        )\n",
    "        self.memory.put(response.message)\n",
    "\n",
    "        tool_calls = self.llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "        for tool_call in tool_calls:\n",
    "            if self._verbose:\n",
    "                print(f\"Tool call: {tool_call}\")\n",
    "        if not tool_calls:\n",
    "            # all the content should be stored in the context, so just pass along input\n",
    "            return ReportGenerationEvent(input=ev.input)\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.tool_name == self.chunk_retriever_tool.metadata.name:\n",
    "                return ChunkRetrievalEvent(tool_call=tool_call)\n",
    "            elif tool_call.tool_name == self.doc_retriever_tool.metadata.name:\n",
    "                return DocRetrievalEvent(tool_call=tool_call)\n",
    "            else:\n",
    "                return StopEvent(result={\"response\": \"Invalid tool.\"})\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def handle_retrieval(\n",
    "        self, ctx: Context, ev: ChunkRetrievalEvent | DocRetrievalEvent\n",
    "    ) -> InputEvent:\n",
    "        \"\"\"Handle retrieval.\n",
    "\n",
    "        Store retrieved chunks, and go back to agent reasoning loop.\n",
    "\n",
    "        \"\"\"\n",
    "        query = ev.tool_call.tool_kwargs[\"query\"]\n",
    "        if isinstance(ev, ChunkRetrievalEvent):\n",
    "            retrieved_chunks = self.chunk_retriever_tool(query).raw_output\n",
    "        else:\n",
    "            retrieved_chunks = self.doc_retriever_tool(query).raw_output\n",
    "        ctx.data[\"stored_chunks\"].extend(retrieved_chunks)\n",
    "\n",
    "        # synthesize an answer given the query to return to the LLM.\n",
    "        response = self.summarizer.synthesize(query, nodes=retrieved_chunks)\n",
    "        self.memory.put(\n",
    "            ChatMessage(\n",
    "                role=\"tool\",\n",
    "                content=str(response),\n",
    "                additional_kwargs={\n",
    "                    \"tool_call_id\": ev.tool_call.tool_id,\n",
    "                    \"name\": ev.tool_call.tool_name,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # send input event back with updated chat history\n",
    "        return InputEvent(input=self.memory.get())\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def generate_report(\n",
    "        self, ctx: Context, ev: ReportGenerationEvent\n",
    "    ) -> StopEvent:\n",
    "        \"\"\"Generate report.\"\"\"\n",
    "        # given all the context, generate query\n",
    "        response = self.report_gen_summarizer.synthesize(\n",
    "            ctx.data[\"query\"], nodes=ctx.data[\"stored_chunks\"]\n",
    "        )\n",
    "\n",
    "        return StopEvent(result={\"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = ReportGenerationAgent(\n",
    "    chunk_retriever_tool,\n",
    "    doc_retriever_tool,\n",
    "    llm=llm,\n",
    "    report_gen_sllm=report_gen_sllm,\n",
    "    verbose=True,\n",
    "    timeout=120.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_p2VqKBvTaQ84lSQ8oU59cbPo' tool_name='doc_retriever_fn' tool_kwargs={'query': 'Tesla 2021 financial statements assets liabilities'}\n",
      "Step handle_llm_input produced event DocRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_hY4phZeNHTLkkDWqjHCk9lA1' tool_name='doc_retriever_fn' tool_kwargs={'query': 'Apple 2021 financial statements assets liabilities'}\n",
      "Step handle_llm_input produced event DocRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ReportGenerationEvent\n",
      "Running step generate_report\n",
      "Step generate_report produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(\n",
    "    input=\"Tell me about the top-level assets and liabilities for Tesla in 2021, and compare it against those of Apple in 2021. Which company is doing better?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In 2021, Tesla and Apple reported their top-level assets and liabilities in their respective annual reports. Here is a detailed comparison of their financial positions for the year 2021."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tesla (in millions)</th>\n",
       "      <th>Apple (in millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Assets</td>\n",
       "      <td>$62,131</td>\n",
       "      <td>$351,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Liabilities</td>\n",
       "      <td>$30,548</td>\n",
       "      <td>$287,912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category Tesla (in millions) Apple (in millions)\n",
       "0       Total Assets             $62,131            $351,002\n",
       "1  Total Liabilities             $30,548            $287,912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tesla's total assets in 2021 amounted to $62.131 billion, while its total liabilities were $30.548 billion. In comparison, Apple's total assets were significantly higher at $351.002 billion, with total liabilities of $287.912 billion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Total Assets (in billions)</th>\n",
       "      <th>Total Liabilities (in billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>$62.131</td>\n",
       "      <td>$30.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>$351.002</td>\n",
       "      <td>$287.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Total Assets (in billions) Total Liabilities (in billions)\n",
       "0   Tesla                    $62.131                         $30.548\n",
       "1   Apple                   $351.002                        $287.912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "When comparing the financial positions of Tesla and Apple in 2021, it is evident that Apple had a much stronger financial position with significantly higher total assets and liabilities. Apple's total assets were approximately 5.65 times greater than Tesla's, and its total liabilities were about 9.42 times higher than Tesla's. This indicates that Apple had more resources at its disposal and a larger scale of operations compared to Tesla. Therefore, in terms of financial metrics, Apple was doing better than Tesla in 2021."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret[\"response\"].response.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_Xqx4IUccHisGohNp4wQRWYyE' tool_name='chunk_retriever_fn' tool_kwargs={'query': 'Apple gross margin breakdown 2020'}\n",
      "Step handle_llm_input produced event ChunkRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_wTlQF8mnKlSpOsGzVAQm8scx' tool_name='chunk_retriever_fn' tool_kwargs={'query': 'Apple gross margin breakdown 2021'}\n",
      "Step handle_llm_input produced event ChunkRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_Xh1liurupCNVIXavyS4v03gQ' tool_name='chunk_retriever_fn' tool_kwargs={'query': 'Apple gross margin breakdown 2022'}\n",
      "Step handle_llm_input produced event ChunkRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_djIy0AZLrTkqg2qCoTO9zsRF' tool_name='chunk_retriever_fn' tool_kwargs={'query': 'Apple gross margin breakdown 2023'}\n",
      "Step handle_llm_input produced event ChunkRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ReportGenerationEvent\n",
      "Running step generate_report\n",
      "Step generate_report produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(\n",
    "    input=\"Tell me about the gross margin breakdown of Apple 2020-2023.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The gross margin breakdown of Apple Inc. from 2020 to 2023 provides insights into the company's profitability across its product and service lines. The gross margin is a critical financial metric that indicates the difference between sales and the cost of goods sold, reflecting the efficiency of production and pricing strategies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2023</th>\n",
       "      <th>2022</th>\n",
       "      <th>2021</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Products</td>\n",
       "      <td>$108,803</td>\n",
       "      <td>$114,728</td>\n",
       "      <td>$105,126</td>\n",
       "      <td>$69,461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Services</td>\n",
       "      <td>$60,345</td>\n",
       "      <td>$56,054</td>\n",
       "      <td>$47,710</td>\n",
       "      <td>$35,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total gross margin</td>\n",
       "      <td>$169,148</td>\n",
       "      <td>$170,782</td>\n",
       "      <td>$152,836</td>\n",
       "      <td>$104,956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           2023      2022      2021      2020\n",
       "0            Products  $108,803  $114,728  $105,126   $69,461\n",
       "1            Services   $60,345   $56,054   $47,710   $35,495\n",
       "2  Total gross margin  $169,148  $170,782  $152,836  $104,956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The gross margin for products and services has shown a consistent increase over the years, with a notable rise in services gross margin. This indicates a growing contribution of services to the overall profitability of the company."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2023</th>\n",
       "      <th>2022</th>\n",
       "      <th>2021</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Products</td>\n",
       "      <td>36.5%</td>\n",
       "      <td>36.3%</td>\n",
       "      <td>35.3%</td>\n",
       "      <td>31.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Services</td>\n",
       "      <td>70.8%</td>\n",
       "      <td>71.7%</td>\n",
       "      <td>69.7%</td>\n",
       "      <td>66.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total gross margin percentage</td>\n",
       "      <td>44.1%</td>\n",
       "      <td>43.3%</td>\n",
       "      <td>41.8%</td>\n",
       "      <td>38.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   2023   2022   2021   2020\n",
       "0                       Products  36.5%  36.3%  35.3%  31.5%\n",
       "1                       Services  70.8%  71.7%  69.7%  66.0%\n",
       "2  Total gross margin percentage  44.1%  43.3%  41.8%  38.2%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The gross margin percentage for both products and services has also increased, reflecting improved efficiency and cost management. The services segment, in particular, has a significantly higher gross margin percentage compared to products, highlighting its higher profitability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "In 2023, the gross margin for products decreased compared to 2022 due to the weakness in foreign currencies relative to the U.S. dollar and lower product volumes. However, the gross margin percentage increased due to cost savings and a different product mix. For services, the gross margin increased due to higher net sales, although the gross margin percentage slightly decreased due to higher service costs and the impact of foreign currency fluctuations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Overall, the data indicates that while the products segment faces challenges related to currency fluctuations and volume changes, the services segment continues to grow and contribute significantly to Apple's profitability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret[\"response\"].response.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Tool call: tool_id='call_ZupQtlUffBFo2oTF72ngp8aH' tool_name='doc_retriever_fn' tool_kwargs={'query': 'Tesla summary 2023'}\n",
      "Step handle_llm_input produced event DocRetrievalEvent\n",
      "Running step handle_retrieval\n",
      "Step handle_retrieval produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ReportGenerationEvent\n",
      "Running step generate_report\n",
      "Step generate_report produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(\n",
    "    input=\"Give me a condensed summary of Tesla in 2023\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Tesla, Inc. is a Delaware corporation headquartered in Austin, Texas, that designs, develops, manufactures, sells, and leases high-performance fully electric vehicles and energy generation and storage systems. The company operates through two main segments: automotive and energy generation and storage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "In 2023, Tesla produced 1,845,985 consumer vehicles and delivered 1,808,581 consumer vehicles. The company manufactures five different consumer vehicles: Model 3, Model Y, Model S, Model X, and Cybertruck. Additionally, Tesla began early production and deliveries of the Tesla Semi, a commercial electric vehicle."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vehicles Produced</td>\n",
       "      <td>1,845,985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vehicles Delivered</td>\n",
       "      <td>1,808,581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric      Value\n",
       "0   Vehicles Produced  1,845,985\n",
       "1  Vehicles Delivered  1,808,581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tesla's energy generation and storage segment includes products like Powerwall and Megapack, which are lithium-ion battery energy storage products. In 2023, Tesla deployed 14.72 GWh of energy storage products and 223 megawatts of solar energy systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Energy Storage Products Deployed</td>\n",
       "      <td>14.72 GWh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solar Energy Systems Deployed</td>\n",
       "      <td>223 MW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Metric      Value\n",
       "0  Energy Storage Products Deployed  14.72 GWh\n",
       "1     Solar Energy Systems Deployed     223 MW"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Financially, Tesla recognized total revenues of $96.77 billion in 2023, an increase of $15.31 billion compared to the prior year. The company's net income attributable to common stockholders was $15.00 billion, which included a one-time non-cash tax benefit of $5.93 billion for the release of valuation allowance on certain deferred tax assets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Revenues</td>\n",
       "      <td>$96.77 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Net Income</td>\n",
       "      <td>$15.00 billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric           Value\n",
       "0  Total Revenues  $96.77 billion\n",
       "1      Net Income  $15.00 billion"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tesla's cash and cash equivalents and investments totaled $29.09 billion at the end of 2023, representing an increase of $6.91 billion from the end of 2022. The company continues to invest in expanding its manufacturing capacity, developing new products, and enhancing its service and charging infrastructure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tesla operates several manufacturing facilities globally, including Gigafactory Texas, Fremont Factory, Gigafactory Nevada, Gigafactory Berlin-Brandenburg, Gigafactory Shanghai, and Gigafactory New York. The company is also constructing a new Gigafactory in Monterrey, Mexico."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gigafactory Texas</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>Owned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fremont Factory</td>\n",
       "      <td>Fremont, California</td>\n",
       "      <td>Owned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gigafactory Nevada</td>\n",
       "      <td>Sparks, Nevada</td>\n",
       "      <td>Owned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gigafactory Berlin-Brandenburg</td>\n",
       "      <td>Grunheide, Germany</td>\n",
       "      <td>Owned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gigafactory Shanghai</td>\n",
       "      <td>Shanghai, China</td>\n",
       "      <td>Owned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gigafactory New York</td>\n",
       "      <td>Buffalo, New York</td>\n",
       "      <td>Leased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Megafactory</td>\n",
       "      <td>Lathrop, California</td>\n",
       "      <td>Leased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Facility             Location  Status\n",
       "0               Gigafactory Texas        Austin, Texas   Owned\n",
       "1                 Fremont Factory  Fremont, California   Owned\n",
       "2              Gigafactory Nevada       Sparks, Nevada   Owned\n",
       "3  Gigafactory Berlin-Brandenburg   Grunheide, Germany   Owned\n",
       "4            Gigafactory Shanghai      Shanghai, China   Owned\n",
       "5            Gigafactory New York    Buffalo, New York  Leased\n",
       "6                     Megafactory  Lathrop, California  Leased"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tesla's mission is to accelerate the world's transition to sustainable energy. The company emphasizes performance, attractive styling, and safety in its products while striving to lower the cost of ownership for its customers. Tesla continues to develop full self-driving technology and aims to establish an autonomous Tesla ride-hailing network in the future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret[\"response\"].response.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamacloud-demo",
   "language": "python",
   "name": "llamacloud-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
