{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ⚠️ Important Notice\n\nThis notebook (and repository) is deprecated.\n\nFor the latest python examples, please refer to the `llama-cloud-services` repository examples: \nhttps://github.com/run-llama/llama_cloud_services/tree/main/examples\n\n---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inline Citations with LlamaCloud\n",
        "In this notebook we show you how to perform inline citations with LlamaCloud. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install core packages, download files. You will need to upload these documents to LlamaCloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-core\n",
        "!pip install llama-index-embeddings-openai\n",
        "!pip install llama-index-question-gen-openai\n",
        "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
        "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git\n",
        "!pip install llama-parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# download Apple \n",
        "!wget \"https://s2.q4cdn.com/470004039/files/doc_earnings/2023/q4/filing/_10-K-Q4-2023-As-Filed.pdf\" -O data/apple_2023.pdf\n",
        "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2022/q4/_10-K-2022-(As-Filed).pdf\" -O data/apple_2022.pdf\n",
        "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2021/q4/_10-K-2021-(As-Filed).pdf\" -O data/apple_2021.pdf\n",
        "!wget \"https://s2.q4cdn.com/470004039/files/doc_financials/2020/ar/_10-K-2020-(As-Filed).pdf\" -O data/apple_2020.pdf\n",
        "!wget \"https://www.dropbox.com/scl/fi/i6vk884ggtq382mu3whfz/apple_2019_10k.pdf?rlkey=eudxh3muxh7kop43ov4bgaj5i&dl=1\" -O data/apple_2019.pdf\n",
        "\n",
        "# download Tesla\n",
        "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000162828024002390/tsla-20231231-gen.pdf\" -O data/tesla_2023.pdf\n",
        "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000095017023001409/tsla-20221231-gen.pdf\" -O data/tesla_2022.pdf\n",
        "!wget \"https://www.dropbox.com/scl/fi/ptk83fmye7lqr7pz9r6dm/tesla_2021_10k.pdf?rlkey=24kxixeajbw9nru1sd6tg3bye&dl=1\" -O data/tesla_2021.pdf\n",
        "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000156459021004599/tsla-10k_20201231-gen.pdf\" -O data/tesla_2020.pdf\n",
        "!wget \"https://ir.tesla.com/_flysystem/s3/sec/000156459020004475/tsla-10k_20191231-gen_0.pdf\" -O data/tesla_2019.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some OpenAI and LlamaParse details. The OpenAI LLM is used for response synthesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using OpenAI API for embeddings/llms\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": [
        "## Load Documents into LlamaCloud\n",
        "\n",
        "The first order of business is to download the 5 Apple and Tesla 10Ks and upload them into LlamaCloud.\n",
        "\n",
        "You can easily do this by creating a pipeline and uploading docs via the \"Files\" mode.\n",
        "\n",
        "After this is done, proceed to the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define NodeCitationPostProcessor\n",
        "Add node id to metadata to match the citation links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from llama_index.core import QueryBundle\n",
        "from llama_index.core.postprocessor.types import BaseNodePostprocessor\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "\n",
        "\n",
        "class NodeCitationProcessor(BaseNodePostprocessor):\n",
        "    \"\"\"\n",
        "    Append node_id into metadata for citation purpose.\n",
        "    Config SYSTEM_CITATION_PROMPT in your runtime environment variable to enable this feature.\n",
        "    \"\"\"\n",
        "\n",
        "    def _postprocess_nodes(\n",
        "        self,\n",
        "        nodes: List[NodeWithScore],\n",
        "        query_bundle: Optional[QueryBundle] = None,\n",
        "    ) -> List[NodeWithScore]:\n",
        "        for node_score in nodes:\n",
        "            node_score.node.metadata[\"node_id\"] = node_score.node.node_id\n",
        "        return nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define System Citation Prompt\n",
        "Modify the system prompt to add the citation links based on the metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_CITATION_PROMPT = \"\"\"You have provided information from a knowledge base that has been passed to you in nodes of information.\n",
        "Each node has useful metadata such as node ID, file name, page, etc.\n",
        "Please add the citation to the data node for each sentence or paragraph that you reference in the provided information.\n",
        "The citation format is: . [citation:<node_id>]()\n",
        "Where the <node_id> is the unique identifier of the data node.\n",
        "\n",
        "Example:\n",
        "We have two nodes:\n",
        "  node_id: xyz\n",
        "  file_name: llama.pdf\n",
        "  \n",
        "  node_id: abc\n",
        "  file_name: animal.pdf\n",
        "\n",
        "User question: Tell me a fun fact about Llama.\n",
        "Your answer:\n",
        "A baby llama is called \"Cria\" [citation:xyz]().\n",
        "It often live in desert [citation:abc]().\n",
        "It\\\\'s cute animal.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define LlamaCloud Retriever over Documents\n",
        "\n",
        "In this section we define LlamaCloud Retriever over these documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
        "import os\n",
        "\n",
        "index = LlamaCloudIndex(\n",
        "  name=\"apple_tesla_demo_2\",\n",
        "  project_name=\"llamacloud_demo\",\n",
        "  api_key=os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define chunk retriever\n",
        "\n",
        "The chunk-level retriever does vector search with a final reranked set of `rerank_top_n=5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk_retriever = index.as_retriever(\n",
        "    retrieval_mode=\"chunks\",\n",
        "    rerank_top_n=5\n",
        ")\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o-mini\", system_prompt=SYSTEM_CITATION_PROMPT)\n",
        "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
        "    chunk_retriever, \n",
        "    llm=llm,\n",
        "    response_mode=\"tree_summarize\",\n",
        "    node_postprocessors=[NodeCitationProcessor()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate final output matching citations with page labela\n",
        "Given the found nodes, match the page assigned and build a final url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def process_citations_with_sources(response) -> str:\n",
        "    content = str(response)\n",
        "    source_nodes = response.source_nodes\n",
        "\n",
        "    # Create a lookup: citation_id -> page_label\n",
        "    id_to_label = {\n",
        "        str(node.id_): node.metadata.get('page_label', 'unknown')\n",
        "        for node in source_nodes\n",
        "    }\n",
        "\n",
        "    # Track citation order and assign human-friendly numbers\n",
        "    citation_order = {}\n",
        "    citation_counter = 1\n",
        "\n",
        "    def replace(match):\n",
        "        nonlocal citation_counter\n",
        "        citation_id = match.group(1).strip()\n",
        "        if citation_id not in citation_order:\n",
        "            citation_order[citation_id] = citation_counter\n",
        "            citation_counter += 1\n",
        "        number = citation_order[citation_id]\n",
        "        page_label = id_to_label.get(citation_id, 'unknown')\n",
        "        return f\"[{number}](https://fake.url/SampleFile#page={page_label})\"\n",
        "\n",
        "    # Replace complete citations\n",
        "    citation_regex = re.compile(r'\\[citation:([^\\]]+)\\]')\n",
        "    content = citation_regex.sub(replace, content)\n",
        "\n",
        "    # Remove incomplete/broken citation tags\n",
        "    incomplete_regex = re.compile(r'\\[citation:[^\\]]*$')\n",
        "    content = incomplete_regex.sub('', content)\n",
        "\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = query_engine_chunk.query(\"What are the tiny risks for apple 2022\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apple Inc. faces several risks that could impact its business and financial performance in 2022. These include:\n",
            "\n",
            "1. **Foreign Currency Exchange Risks**: The company's financial performance is subject to risks associated with changes in the value of the U.S. dollar relative to local currencies. Fluctuations in foreign currency exchange rates can adversely affect gross margins on products sold internationally, potentially leading to reduced demand if international pricing is raised to offset currency strength [1](https://fake.url/SampleFile#page=19)().\n",
            "\n",
            "2. **Credit Risk**: Apple is exposed to credit risk related to its trade accounts receivable and vendor non-trade receivables. This risk is heightened during economic downturns, especially since a significant portion of its trade receivables is not covered by collateral or credit insurance [1](https://fake.url/SampleFile#page=19)().\n",
            "\n",
            "3. **Supply Chain Risks**: The company relies heavily on single-source suppliers for many components. Any disruptions in the supply chain, whether due to natural disasters, political issues, or supplier financial instability, could adversely affect production and sales [2](https://fake.url/SampleFile#page=12)().\n",
            "\n",
            "4. **Product and Service Quality Risks**: Apple’s products and services may experience design and manufacturing defects, which could harm its reputation and lead to financial liabilities. The complexity of its hardware and software increases the risk of defects that could affect customer satisfaction [2](https://fake.url/SampleFile#page=12)().\n",
            "\n",
            "5. **Macroeconomic Risks**: Global and regional economic conditions significantly impact Apple’s performance. Factors such as inflation, recession, and changes in consumer confidence can adversely affect demand for its products and services [3](https://fake.url/SampleFile#page=8)().\n",
            "\n",
            "6. **Regulatory and Compliance Risks**: The company is subject to various U.S. and international laws regarding data protection and privacy. Noncompliance with these laws could result in significant penalties and harm to its reputation [4](https://fake.url/SampleFile#page=18)().\n",
            "\n",
            "These risks, while potentially small in individual impact, can collectively pose significant challenges to Apple's operations and financial health in 2022.\n"
          ]
        }
      ],
      "source": [
        "content = process_citations_with_sources(response)\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}